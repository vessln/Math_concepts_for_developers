%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
import time
import mmh3
import hashlib
import bitarray
import math
import pandas as pd


pip install mmh3


pip install bitarray


















































n = np.arange(1, 7)

constant = np.ones_like(n)
logaritmic = np.log(n)
linear = n
log_linear = n * np.log(n)
quadratic = n ** 2
exponential = 2 ** n

plt.figure(figsize=(8, 5))
plt.plot(n, constant, label="O(1)", marker="o")
plt.plot(n, logaritmic, label="O(log n)", marker="o")
plt.plot(n, linear, label="O(n)", marker="o")
plt.plot(n, log_linear, label="O(n log n)", marker="o")
plt.plot(n, quadratic, label="O(n^2)", marker="o")
plt.plot(n, exponential, label="O(2^n)", marker="o")

plt.xlabel("Input data (n)")
plt.ylabel("Operations")
plt.title("Time Complexities")
plt.legend()
plt.grid(True)
plt.show()







































































# example data to hash:
key = "vesi"

# different seed values:
seed1 = 47
seed2 = 123

# generate and return 32-bit integer hash value with sign:
hash_value1 = mmh3.hash(key, seed1)
hash_value2 = mmh3.hash(key, seed2)

print(f"The hash value with seed1 is: {hash_value1}")
print(f"The hash value with seed2 is: {hash_value2}")


# function to measure time of MurmurHash3:
def test_murmurhash3(data):
    start_time = time.time()
    hash_value = mmh3.hash(data)
    end_time = time.time()
    measured_time = end_time - start_time
    
    return hash_value, measured_time

# function to measure time of MD5:
def test_md5(data):
    start_time = time.time()
    hash_object = hashlib.md5(data)
    hash_value = hash_object.hexdigest()
    end_time = time.time()
    measured_time = end_time - start_time
    
    return hash_value, measured_time

# sample data:
data = b"Bloom filters"

# number of iterations:
num_iterations = 10000

# measure time for MMH3:
mmh3_times = []
for _ in range(num_iterations):
    _, time_taken = test_murmurhash3(data)
    mmh3_times.append(time_taken)
    sum_mmh3_times = sum(mmh3_times)

# measure time for MD5:
md5_times = []
for _ in range(num_iterations):
    _, time_taken = test_md5(data)
    md5_times.append(time_taken)
    sum_md6_times = sum(md5_times)

avg_time_mmh3 = sum_mmh3_times / num_iterations
avg_time_md5 = sum_md6_times / num_iterations

print(f"Average time taken for MurmurHash3: {avg_time_mmh3} seconds")
print(f"Average time taken for MD5: {avg_time_md5} seconds")


labels = ["MurmurHash3", "MD5"]
avg_times = [avg_time_mmh3, avg_time_md5]
colors = ["red", "green"]

plt.bar(labels, avg_times, color=colors)
plt.ylabel("average time, sec")
plt.title("Comparison of MurmurHash3 vs MD5")
plt.show()



































class BloomFilter:
    def __init__(self, n, error_rate, base_seed=0):
        self.n = n # predicted number of elements that i want to store in bit array
        self.error_rate = error_rate # desired maximum false positive rate
        self.base_seed = base_seed # base seed for hash functions
        
        self._actual_num_bits = self._calculate_num_bits(n, error_rate) # calculated number of bits in bit array (m)
        self._num_hashes = self._calculate_num_hashes(self._actual_num_bits, n) # calculated number of hash functions needed
        self.bit_array = bitarray.bitarray(self._actual_num_bits) # set bit array
        self.bit_array.setall(0)
        self.elements = set()
        
    def insert(self, element):
        for i in range(self._num_hashes):
            # generates a hash value for the element and sets the corresponding bit to 1
            seed = self.base_seed + i
            hash_value = mmh3.hash(element, seed) % self._actual_num_bits
            self.bit_array[hash_value] = 1
            self.elements.add(element)
        
    def lookup(self, element):
        for i in range(self._num_hashes):
            # generates a hash value for the element and checks if the corresponding bit is 1
            seed = self.base_seed + i
            hash_value = mmh3.hash(element, seed) % self._actual_num_bits
            
            if self.bit_array[hash_value] == 0:
                return "Not in array" # if any of the bits is 0, the element is definitely not present
                
        return "Maybe in array" # if all the bits are 1, the element may be present
    
    def _calculate_num_bits(self, n, error_rate):
        # calculates the number of bits needed for a given capacity and error rate
        actual_num_bits = - (n * math.log(error_rate)) / (math.log(2) ** 2)
        return int(actual_num_bits)
    
    def _calculate_num_hashes(self, actual_num_bits, n):
        # calculates the number of hash functions needed for a given (expected) number of bits and actual number of bits
        num_hashes = (actual_num_bits / n) * math.log(2)
        return int(num_hashes)


n = 100
error = 0.01

bf = BloomFilter(n, error, base_seed=47)

for el in ["vesi", "ivan", "petio", "pet", "asdas", "ojar"]:
    bf.insert(el)

print(bf.lookup("vesi")) 
print(bf.lookup("alex")) 
print(bf.lookup("pet")) 








class TestBF:
    def __init__(self, n, hash_count):
        self.n = n
        self.hash_count = hash_count
        self.bit_array = bitarray.bitarray(n)
        self.bit_array.setall(0)
        
    def insert(self, element):
        for i in range(self.hash_count):
            hash_value = mmh3.hash(element) % self.n
            self.bit_array[hash_value] = 1
        
    def lookup(self, element):
        for i in range(self.hash_count):
            hash_value = mmh3.hash(element) % self.n
            
            if self.bit_array[hash_value] == 0:
                return False
                
        return True


def calculate_bloom_filter_parameters(n, p):
    m = - (n * math.log(p)) / (math.log(2) ** 2)
    k = math.ceil((m / n) * math.log(2))
    
    return int(m), k

def calculate_false_positive_probability(m, k, n):
    inner_expression = (1 - (1 - 1/m) ** (k * n))
    Pfp = inner_expression ** k

    return Pfp


# measure times for inserting different number of elements in Bloom filter with n = 100000:

def measure_insertion_time(bloom_filter, num_elements):
    start_time = time.perf_counter()
    for i in range(num_elements):
        item = f"item{i}"
        bloom_filter.insert(item)
    end_time = time.perf_counter()
    
    return end_time - start_time


# parameters
n = 100000
all_p = [0.001, 0.01, 0.1]
element_counts = [100, 1000, 5000, 10000, 20000, 50000, 70000, 100000]
times = []

# initialize a dictionary to store times for each p
times_dict = {p: [] for p in all_p}

for p in all_p:
    m, k = calculate_bloom_filter_parameters(n, p)
    for num_elements in element_counts:
        bf_i = TestBF(m, k)
        elapsed_time = measure_insertion_time(bf_i, num_elements)
        times_dict[p].append(elapsed_time)


plt.figure(figsize=(8, 5))
for p in all_p:
    plt.plot(element_counts, times_dict[p], marker="o", label=f"p = {p}")

plt.xlabel("Number of inserted elements")
plt.ylabel("Insertion time, sec")
plt.title("(1)   Insertion time vs Number of elements for different error rates")
plt.grid(True)
plt.legend()
plt.show()





# measure lookup times for different p values and incresing numbers of inserted elements
def measure_lookup_time(bloom_filter, num_elements):
    start_time = time.perf_counter()
    for i in range(num_elements):
        item = f"item{i}"
        bloom_filter.lookup(item)
    end_time = time.perf_counter()
    
    return end_time - start_time


# parameters
n = 100000
all_p = [0.01, 0.05, 0.1]
element_counts = [100, 1000, 5000, 10000, 20000, 50000, 70000, 100000]

lookup_times_dict = {p: [] for p in all_p}

for p in all_p:
    m, k = calculate_bloom_filter_parameters(n, p)
    for num_elements in element_counts:
        bf_i = TestBF(m, k)
        
        for i in range(num_elements):
            item = f"item{i}"
            bf_i.insert(item)
            
        elapsed_time = measure_lookup_time(bf_i, num_elements)
        lookup_times_dict[p].append(elapsed_time)


plt.figure(figsize=(8, 5))
for p in all_p:
    plt.plot(element_counts, lookup_times_dict[p], marker="o", label=f"p = {p}")

plt.xlabel("Number of elements")
plt.ylabel("Lookup time, sec")
plt.title("(2)   Lookup time vs Number of elements for different p values")
plt.grid(True)
plt.legend()
plt.show()








def compare_m_and_n(p):
    n_values = np.linspace(100, 10000, num=10)
    m_values = - (n_values * np.log(p)) / (np.log(2) ** 2)

    plt.figure(figsize=(8, 5))
    plt.plot(n_values, m_values, color="blue")
    plt.title("(3)   Number of expected elements vs actual size of Bloom filter")
    plt.xlabel("Number of elements (n)")
    plt.ylabel("Size of bit array (m)")
    plt.grid(True)
    plt.show()

compare_m_and_n(p = 0.01)


def compare_m_and_p(n):
    p_values = np.linspace(0.01, 0.1, 100) 
    m_values = - n * np.log(p_values) / (np.log(2) ** 2)
    
    plt.figure(figsize=(8, 5))
    plt.plot(p_values, m_values, color="red")
    plt.xlabel("False positive rate (p)")
    plt.ylabel("Size of Bloom filter (m)")
    plt.title("(4)  Size of bit array vs different false positive rates")
    plt.grid(True)
    plt.show()

compare_m_and_p(n = 10000)








n = 10000
p = 0.01

m, k = calculate_bloom_filter_parameters(n, p)
Pfp = calculate_false_positive_probability(m, k, n)

print(f"Number of bits in Bloom filter (m): {m}")
print(f"Number of hash functions (k): {k}")
print(f"False positive probability (Pfp): {Pfp:.6f}")





class TestHashTable:
    def __init__(self):
        self.table = {}
    
    def insert(self, word):
        self.table[word] = True
    
    def lookup(self, word):
        return word in self.table


import sys
def measure_insertion_time(data_structure, words):
    start_time = time.perf_counter()
    for word in words:
        data_structure.insert(word)
    end_time = time.perf_counter()
    
    return end_time - start_time


def measure_lookup_time(data_structure, words):
    start_time = time.perf_counter()
    for word in words:
        data_structure.lookup(word)
    end_time = time.perf_counter()
    
    return end_time - start_time


def calculate_hash_table_memory(hash_table):
    total_size_bytes = sys.getsizeof(hash_table.table)
    total_size_bits = total_size_bytes * 8
    for key in hash_table.table:
        total_size_bits += sys.getsizeof(key) * 8
        total_size_bits += sys.getsizeof(hash_table.table[key]) * 8
        
    return total_size_bits
    

p = 0.01
n_values = np.linspace(100, 10000, num = 10, dtype = int)
bloom_insert_times, hash_insert_times = [], []
bloom_lookup_times, hash_lookup_times = [], []
bloom_memory, hash_memory = [], []

for n in n_values:
    m, k = calculate_bloom_filter_parameters(n, p)
    bloom_filter = TestBF(m, k)
    hash_table = TestHashTable()
    
    words = [f"word{i}" for i in range(n)]
    
    bloom_insert_times.append(measure_insertion_time(bloom_filter, words))
    hash_insert_times.append(measure_insertion_time(hash_table, words))
    bloom_lookup_times.append(measure_lookup_time(bloom_filter, words))
    hash_lookup_times.append(measure_lookup_time(hash_table, words))

    bloom_memory.append(m)
    calculated_hash_memory = calculate_hash_table_memory(hash_table)
    hash_memory.append(calculated_hash_memory)
    

fig, axs = plt.subplots(1, 2, figsize=(20, 6))
axs[0].plot(n_values, bloom_insert_times, label="Bloom filter insert time, sec", marker="o")
axs[0].plot(n_values, hash_insert_times, label="Hash table insert time, sec", marker="x")
axs[0].set_title("Insertion time comparison: Bloom filter vs hash table")
axs[0].set_xlabel("Number of elements (n)")
axs[0].set_ylabel("Insertion time, sec")
axs[0].legend()
axs[0].grid(True)

axs[1].plot(n_values, bloom_lookup_times, label="Bloom filter lookup time, sec", marker="o")
axs[1].plot(n_values, hash_lookup_times, label="Hash table lookup time, sec", marker="x")
axs[1].set_title("Lookup time comparison: Bloom filter vs hash table")
axs[1].set_xlabel("Number of elements (n)")
axs[1].set_ylabel("Lookup time, sec")
axs[1].legend()
axs[1].grid(True)

plt.figure(figsize=(8, 6))
plt.plot(n_values, bloom_memory, label="Bloom filter memory, bits", marker="o")
plt.plot(n_values, hash_memory, label="Hash table memory, bits", marker="x")
plt.title("Memory usage comparison: Bloom filter vs hash table")
plt.xlabel("Number of elements (n)")
plt.ylabel("Memory usage, bits")
plt.legend()
plt.grid(True)

plt.show()

print("Memory consumption:")
print(f"n = {n}: Bloom filter memory = {m} bits, Hash table memory = {calculate_hash_table_memory(hash_table)} bits")

















fruits_file = "fruits.txt"
df = pd.read_csv(fruits_file, header = None, names = ["Fruits"])
print(df.count())

all_fruits = df["Fruits"].str.lower().tolist() 
print(f"{all_fruits}\n")

def test_with_different_parameters(n, p):
    m, k = calculate_bloom_filter_parameters(n, p)
    Pfp = calculate_false_positive_probability(m, k, n)
    
    bloom_filter = TestBF(m, k)
    
    for fruit in all_fruits:
        bloom_filter.insert(fruit)
                
    words_to_check = ["aple", "car", "mang0", "honey", "computer", "lemone", "book", "grapefrut", "banan@", "corn"]
    
    print("Testing for false positives:")
    fp_count = 0
    for word in words_to_check:
        if bloom_filter.lookup(word.lower()):
            print(f"{word} is likely a false positive.")
            fp_count += 1 
        else:
            print(f"{word} is correctly identified as not present.")
            
    print(f"\nNumber of false positives: {fp_count}")
    print(f"Bloom filter parameters: n = {n}, p = {p}, m = {m} bits, k = {k}, Pfp = {Pfp:.6f}\n")


test_with_different_parameters(n = 80, p = 0.001)


test_with_different_parameters(n = 80, p = 0.005)


test_with_different_parameters(n = 80, p = 0.01)


test_with_different_parameters(n = 80, p = 0.1)









